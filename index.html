<html>
  <head>
    <title>Cheng-En Wu's Website</title>
    <script src='js/jquery-1.11.2.min.js'></script>
    <script src='js/bootstrap.min.js'></script>
    <link href='css/bootstrap.min.css' rel='stylesheet'>
    <link href='http://fonts.googleapis.com/css?family=Roboto:400,500,700,900,100italic,100,300,300italic,400italic,500italic,900italic,700italic' rel='stylesheet' type='text/css'>
    <style>
      body {
        font-family: 'sans-serif';
        font-size: 16px;
        background-color: rgb(232, 226, 214);
        color: #4F6071;
      }
      .color1 {
        background-color: #CCC;
      }
      #header {
        width: 100%;
        height: 360px;
        /* background-color: #F0EAD6 */
        background: rgb(34,193,195);
        background: linear-gradient(240deg, rgba(34,193,195,1) 0%, rgba(253,187,45,1) 100%);
        /* background-color: #b30000; */
        /* background-color: #CCC; */
      }
      #header-inner {
        position: absolute;
        width: 70%;
        left: 30%;
        top: 150px;
      }
      .img-me {
        border: 3px solid white;
        float: left;
        height: 200px;
      }
      .header-text {
        margin-top: 60px;
        margin-left: 220px;
      }
      .header-text-name {
        font-weight: bold;
        font-size: 40px;
      }
      .header-text-email {
        font-size: 20px;
        font-style: italic;
      }
      .header-text-desc {
        font-size: 20px;
      }
      #contact-info {
        position: absolute;
        left: 80%;
        width: 20%;
        top: 360px;
        height: 100px;
        background-color: #EEE;
      }
      .vspace {
        margin-bottom: 20px;
      }
      .vspace-top {
        margin-top: 30px;
      }
      .paper-image {
        width: 150px;
      }
      .paper-title {
        font-weight: bold;
      }
      .paper-authors {
        font-style: italic;
      }
      .paper-link {
      }
    </style>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-50623594-1', 'auto');
      ga('send', 'pageview');
    </script>
  </head>
  <body>
    <div id='header'>
      <div id='header-inner'>
        <img src='images/Cheng-En.jpg' class='img-circle img-me'>
        <div class='header-text'>
          <div class='header-text-name'>
            Cheng-En Wu
          </div>
          <div class='header-text-email'>
            cwu356 at wisc dot edu
          </div>
          <div>
            <a href="https://github.com/CEWu">[GitHub]</a>
            <a href="https://scholar.google.com/citations?user=4SQ9RDUAAAAJ&hl=en">[Google Scholar]</a>
          </div>
        </div>
      </div>
    </div>

    <div class='container'>
      <div class='col-xs-10 col-md-offset-1'>
        <div class='row'>
          <h1>About</h1>
          <div class='vspace'>
            I am a Research Scientist at the Center for Advanced AI, Accenture</a>, where I work on LLM post-training.
            <br><br>I got my ECE Ph.D. from <a href="https://www.wisc.edu/" target='_blank'>University of Wisconsinâ€“Madison</a>, where I was advised by
            <a href="https://scholar.google.com/citations?user=Yy4gO-QAAAAJ" target='_blank'>Pedro Morgado</a> and
            <a href="https://scholar.google.com/citations?user=5CAjat0AAAAJ&hl=en" target='_blank'>Yu Hen Hu.</a>
            <br>My research interests lie at the intersection of computer vision and deep learning. I focus on Code
            Large Language Models (Code LLMs), Multimodal Large Language Models (MLLMs), and improving the efficiency of self-supervised learning models in both training and inference. <br><br>


            I've been fortunate to work with really great people along the way. From Spring to Winter 2024, I was a research intern at <a href="https://www.microsoft.com/en-us/research/group/azure-research/" target='_blank'>
              Microsoft</a>, working with <a href="https://scholar.google.com/citations?user=hJrIyCwAAAAJ&hl=en" target='_blank'>Yunsheng Li</a>,
              <a href="https://scholar.google.com/citations?user=6y8YsE8AAAAJ&hl=en" target='_blank'>Weijian Xu</a>, and
              <a href="https://scholar.google.com/citations?user=cOPQtYgAAAAJ&hl=zh-CN" target='_blank'>Mengchen Liu</a>. In Summer 2022, I was a research intern at <a href="https://lifeattiktok.com/" target='_blank'>
            TikTiok</a>, working with <a href="https://scholar.google.com/citations?hl=en&user=DxPjkDoAAAAJ&view_op=list_works" target='_blank'>Yu Tian</a>, 
            <a href="https://scholar.google.com.hk/citations?hl=en&user=XptEO8oAAAAJ&view_op=list_works" target='_blank'>Linjie Yang</a>, 
            <a href="https://scholar.google.com/citations?user=6vBNzOsAAAAJ" target='_blank'>Haichao Yu</a> and 
            <a href="https://scholar.google.com/citations?user=ghmgyewAAAAJ&hl=en" target='_blank'>Heng Wang</a>.
            In Summer 2021, I was a research intern at <a href="https://www.nec-labs.com/research-departments/machine-learning/machine-learning-home" target='_blank'>
            NEC Labs America </a>, 
            working with <a href="https://www.nec-labs.com/farley-lai" target='_blank'>Farlay Lai</a> and 
            <a href="https://www.nec-labs.com/asim-kadav" target='_blank'>Asim Kadav</a>.
            At <a href="https://www.iis.sinica.edu.tw/index_en.html" target='_blank'>
            Academia Sinica</a>, 
            I was a research assistant working with <a href="https://homepage.iis.sinica.edu.tw/pages/song/vita_en.html"target='_blank'>Chu-Song Chen</a>. 
            I graduated from <a href="http://dcs-en.site.nthu.edu.tw/index.php" target='_blank'>National Tsing Hua University</a>
            with an M.S. in Computer Science,
            where I was advised by <a href="http://dcs-en.site.nthu.edu.tw/p/405-1010-9872,c1614.php" target='_blank'>Jia-Shung Wang</a>.
            <!-- <br><br>More details, please see my
            <a href="https://cewu.github.io/files/Cheng-En_Wu_CV_2511.pdf" target='_blank'>
            CV</a> (updated: November 2025). -->

        </div>
        <div class='row'>
          <h1>Publications</h1>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/25_NeurIPSW_MCPbench.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers
              </div>
              <div class='paper-authors'>
                <font color=#707070>Zhenting Wang, Qi Chang, Hemani Patel, Shashank Biju,</font> <b>Cheng-En Wu</b>, <font color=#707070>Quan Liu, Aolin Ding, Alireza Rezazadeh, Ankit Shah, Yujia Bao, Eugene Siow</font>
              </div>
              <div>
                arXiv, 2025
              </div>
              <div>
                <a href="https://arxiv.org/abs/2508.20453">[paper]</a>
                <a href="https://github.com/Accenture/mcp-bench">[code]</a>
              </div>
            </div>
          </div>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/25_arxiv_audio.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                Scaling Up Audio-Synchronized Visual Animation: An Efficient Training Paradigm
              </div>
              <div class='paper-authors'>
                <font color=#707070>Lin Zhang, Zefan Cai, Yufan Zhou, Shentong Mo, Jinhong Lin,</font> <b>Cheng-En Wu</b>, <font color=#707070>Yibing Wei, Yijing Zhang, Ruiyi Zhang, Wen Xiao, Tong Sun, Junjie Hu, Pedro Morgado</font>
              </div>
              <div>
                arXiv, 2025
              </div>
              <div>
                <a href="https://arxiv.org/abs/2508.03955v1">[paper]</a>
              </div>
            </div>
          </div>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/25_ICCV_trackverse.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                TrackVerse: A Large-Scale Object-Centric Video Dataset for Image-Level Representation Learning
              </div>
              <div class='paper-authors'>
                <font color=#707070>Yibing Wei, Samuel Church, Victor Suciu, Jinhong Lin,</font> <b>Cheng-En Wu</b>, <font color=#707070>Pedro Morgado</font>
              </div>
              <div>
                International Conference on Computer Vision <font color=#0000ff>(ICCV)</font>, 2025
              </div>
              <div>
                <a href="https://openaccess.thecvf.com/content/ICCV2025/papers/Wei_TrackVerse_A_Large-Scale_Object-Centric_Video_Dataset_for_Image-Level_Representation_Learning_ICCV_2025_paper.pdf">[paper]</a>
                <a href="https://github.com/MMPLab/TrackVerse">[code]</a>
              </div>
            </div>
          </div>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/25_CVPR_warmup_thumb.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                From Prototypes to General Distributions: An Efficient Curriculum for Masked Image Modeling
              </div>
              <div class='paper-authors'>
                Jinhong Lin*, <b>Cheng-En Wu*</b>, <font color=#707070> Huanran Li, Jifan Zhang, Yu Hen Hu, Pedro Morgado</font> (*equal contribution)
              </div>
              <div>
                Conference on Computer Vision and Pattern Recognition <font color=#0000ff>(CVPR)</font>, 2025
              </div>
              <div>
                <a href="https://arxiv.org/abs/2411.10685">[paper]</a>
                <!-- <a href="https://github.com/CEWu/PTNL">[code]</a> -->
              </div>
              <div>
                <!-- <a href="http://www.apsipa.org/proceedings/2020/pdfs/0001594.pdf">[paper]</a> -->
              </div>
            </div>
          </div>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/25_WACV_patchrank_thumb.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                Patch Ranking: Efficient CLIP by Learning to Rank Local Patches
              </div>
              <div class='paper-authors'>
                <b>Cheng-En Wu</b>, <font color=#707070> Jinhong Lin, Yu Hen Hu, Pedro Morgado</font>
              </div>
              <div>
                Winter Conference on Applications of Computer Vision  <font color=#0000ff>(WACV)</font>, 2025
              </div>
              <div>
                <a href="https://arxiv.org/abs/2409.14607">[paper]</a>
                <!-- <a href="https://github.com/CEWu/PTNL">[code]</a> -->
              </div>
              <div>
                <!-- <a href="http://www.apsipa.org/proceedings/2020/pdfs/0001594.pdf">[paper]</a> -->
              </div>
            </div>
          </div>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/24_NeurIPS_acc_thumb.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                Accelerating Augmentation Invariance Pretraining
              </div>
              <div class='paper-authors'>
                Jinhong Lin*, <b>Cheng-En Wu*</b>, <font color=#707070> Yibing Wei, Pedro Morgado</font> (*equal contribution)
              </div>
              <div>
                Conference on Neural Information Processing Systems <font color=#0000ff>(NeurIPS)</font>, 2024
              </div>
              <div>
                <a href="https://arxiv.org/abs/2410.22364">[paper]</a>
                <!-- <a href="https://github.com/CEWu/PTNL">[code]</a> -->
              </div>
              <div>
                <!-- <a href="http://www.apsipa.org/proceedings/2020/pdfs/0001594.pdf">[paper]</a> -->
              </div>
            </div>
          </div>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/23_ICCV_PTNL_thumb.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                Why Is Prompt Tuning for Vision-Language Models Robust to Noisy Labels?
              </div>
              <div class='paper-authors'>
                <b>Cheng-En Wu</b>, <font color=#707070> Yu Tian, Haichao Yu, Heng Wang, Pedro Morgado, Yu Hen Hu, Linjie Yang</font>
              </div>
              <div>
                International Conference on Computer Vision <font color=#0000ff>(ICCV)</font>, 2023
              </div>
              <div>
                <a href="https://arxiv.org/abs/2307.11978">[paper]</a>
                <a href="https://github.com/CEWu/PTNL">[code]</a>
              </div>
              <div>
                <!-- <a href="http://www.apsipa.org/proceedings/2020/pdfs/0001594.pdf">[paper]</a> -->
              </div>
            </div>
          </div>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/22_CVPRW_CPR_thumb.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                Self-supervised Video Representation Learning with Cascade Positive Retrieval
              </div>
              <div class='paper-authors'>
                <b>Cheng-En Wu</b>, <font color=#707070> Farley Lai, Yu Hen Hu, Asim Kadav</font>
              </div>
              <div>
                L3D-IVU Workshop at Conference on Computer Vision and Pattern Recognition <font color=#0000ff>(CVPR)</font>, 2022
              </div>
              <div>
                <a href="https://arxiv.org/pdf/2201.07989.pdf">[paper]</a>
                <a href="https://github.com/necla-ml/CPR">[code]</a>
              </div>
              <div>
                <!-- <a href="http://www.apsipa.org/proceedings/2020/pdfs/0001594.pdf">[paper]</a> -->
              </div>
            </div>
          </div>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/20_APSIPA_mergeing_thumb.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                Merging Well-Trained Deep CNN Models for Efficient Inference
              </div>
              <div class='paper-authors'>
                <b>Cheng-En Wu</b>, <font color=#707070>Jia-Hong Lee, Timmy ST Wan, Yi-Ming Chan, Chu-Song Chen</font>
              </div>
              <div>
                Asia-Pacific Signal and Information Processing Association Annual Summit and Conference <font color=#0000ff>(APSIPA)</font>, 2020
              </div>
              <div>
                <a href="http://www.apsipa.org/proceedings/2020/pdfs/0001594.pdf">[paper]</a>
              </div>
            </div>
          </div>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/20_APSIPA_CondConv_thumb.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                Extending Conditional Convolution Structures For Enhancing Multitasking Continual Learning
              </div>
              <div class='paper-authors'>
                <font color=#707070>*Cheng-Hao Tu, </font> <b>*Cheng-En Wu</b>, <font color=#707070>Chu-Song Chen</font> (*equal contribution)
              </div>
              <div>
                Asia-Pacific Signal and Information Processing Association Annual Summit and Conference <font color=#0000ff>(APSIPA)</font>, 2020
              </div>
              <div>
                <a href="http://www.apsipa.org/proceedings/2020/pdfs/0001605.pdf">[paper]</a>
                <a href="https://github.com/ivclab/CondConvContinual">[code]</a>
              </div>
            </div>
          </div>

          <div class='row vspace-top'>
              <div class='col-xs-3 text-center'>
                <img class='paper-image' src='images/19_NeurIPS_thumb.png'>
              </div>
              <div class='col-xs-9'>
                <div class='paper-title'>
                  Compacting, Picking and Growing for Unforgetting Continual Learning
                </div>
                <div class='paper-authors'>
                  <font color=#707070>Steven C. Y. Hung, Cheng-Hao Tu,</font> <b>Cheng-En Wu</b>, <font color=#707070>Chien-Hung Chen, Yi-Ming Chan, Chu-Song Chen</font>
                </div>
                <div>
                    Conference on Neural Information Processing Systems <font color=#0000ff>(NeurIPS)</font>, 2019
                </div>
                <div>
                  <a href="http://papers.nips.cc/paper/9518-compacting-picking-and-growing-for-unforgetting-continual-learning.pdf">[paper]</a>
                  <a href="https://github.com/ivclab/CPG">[code]</a>
                </div>
              </div>
            </div>

            <div class='row vspace-top'>
                <div class='col-xs-3 text-center'>
                  <img class='paper-image' src='images/19_MMSP_thumb.png'>
                </div>
                <div class='col-xs-9'>
                  <div class='paper-title'>
                    IMMVP: An Efficient Daytime and NighttimeOn-Road Object Detector
                  </div>
                  <div class='paper-authors'>
                    <b>Cheng-En Wu</b>, <font color=#707070>Yi-Ming Chan, Chien-Hung Chen, Wen-Cheng Chen, Chu-Song Chen</font>
                  </div>
                  <div>
                      IEEE International Workshop on Multimedia Signal Processing <font color=#0000ff>(MMSP)</font>, 2019
                  </div>
                  <div>
                    <a href="https://arxiv.org/pdf/1910.06573.pdf">[paper]</a>
                  </div>
                </div>
              </div>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/19_EMC2_thumb.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                On Merging MobileNets for Efficient Multitask Inference
              </div>
              <div class='paper-authors'>
                <b>Cheng-En Wu</b>, <font color=#707070>Yi-Ming Chan, Chu-Song Chen</font>
              </div>
              <div>
                EMC2 Workshop at IEEE International Symposium on high Performance Computer Architecture <font color=#0000ff>(HPCA)</font>, 2019
              </div>
              <div>
                <a href="https://cewu.github.io/papers/19_EMC2/Merging_MobileNets.pdf">[paper]</a>
                <a href="https://github.com/ivclab/Merging-MobileNets-for-Multitask">[code]</a>
              </div>
            </div>
          </div>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/17_ICS2_thumb.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                  Traffic pattern modeling, trajectory classification 
                  and vehicle tracking within urban intersections
              </div>
              <div class='paper-authors'>
                  <b>Cheng-En Wu</b>, <font color=#707070>Wen-Yen Yang, Hai-Che Ting, Jia-Shung Wang</font>
              </div>
              <div>
                IEEE International Smart Cities Conference <font color=#0000ff>(ISC2)</font>, 2017
              </div>
              <div>
                <a href="https://cewu.github.io/papers/17_ICS2/Vehicle_tracking_ICS2_2017.pdf">[paper]</a>
              </div>
            </div>
          </div>
        </div>


        <div class='row vspace-top'>
          <h1>Work Experience</h1>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/logos/microsoft.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                <br />
                Microsoft
              </div>
              <div class='paper-authors'>
                Research Intern
              </div>
              <div>
                Feb. 2024 - Dec. 2024
              </div>
              <div>
                Redmond, WA
              </div>
            </div>
          </div>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/logos/tiktok.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                <br />
                TikTok
              </div>
              <div class='paper-authors'>
                Research Intern
              </div>
              <div>
                May 2022 - Aug. 2022
              </div>
              <div>
                San Jose, WA
              </div>
            </div>
          </div>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/logos/nec.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                <br />
                NEC Labs America
              </div>
              <div class='paper-authors'>
                Research Intern
              </div>
              <div>
                May 2021 - Aug. 2021
              </div>
              <div>
                Princeton, NJ
              </div>
            </div>
          </div>

          <div class='row vspace-top'>
              <div class='col-xs-3 text-center'>
                <img class='paper-image' src='images/logos/sinica.png'>
              </div>
              <div class='col-xs-9'>
                <div class='paper-title'>
                  <br />
                  Academia Sinica
                </div>
                <div class='paper-authors'>
                  Research Assistant
                </div>
                <div>
                  Mar. 2018 - Aug. 2020
                </div>
                <div>
                  Taipei, Taiwan
                </div>
              </div>
            </div>
         <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/logos/mtk_circle.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                <br />
                MediaTek Inc.
              </div>
              <div class='paper-authors'>
                Software Engineer
              </div>
              <div>
                Mar. 2017 - Mar. 2018
              </div>
              <div>
                Hsinchu, Taiwan
              </div>
            </div>
          </div>
          
          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/logos/realtek_circle.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                <br />
                Realtek Inc.
              </div>
              <div class='paper-authors'>
                Software Engineer
              </div>
              <div>
                Dec. 2016 - Mar. 2017
              </div>
              <div>
                Hsinchu, Taiwan
              </div>
            </div>
          </div>
          <div class='row vspace-top'>
              <div class='col-xs-3 text-center'>
                <img class='paper-image' src='images/logos/GO-Trust_circle.png'>
              </div>
              <div class='col-xs-9'>
                <div class='paper-title'>
                  <br />
                  GOTrust Technology Inc.
                </div>
                <div class='paper-authors'>
                  Software Engineer
                </div>
                <div>
                  Jan. 2014 - Jun. 2014
                </div>
                <div>
                  Taichung, Taiwan
                </div>
              </div>
            </div>
        </div>
        <!-- <div class='row vspace-top'>
          <h1>Education</h1>
          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/logos/nthu.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                <br />
                <br />
                National Tsing Hua University
              </div>
              <div class='paper-authors'>
                M.S. in Computer Science
              </div>
            </div>
          </div>
          
          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='images/logos/ntust.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                <br />
                <br />
                National Taiwan University of Science and Technology
              </div>
              <div class='paper-authors'>
                B.S. in Electrical and Computer Engineering
              </div>
            </div>
          </div>
        </div> -->
        <div class='row vspace-top'></div>
      </div>
    </div>
    <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=TiK68FgWerpJDGXGHnTJ-YOUitDvVyhApBkOlKrdFTU&co=e8e2d6"></script>
  </body>
</html>
